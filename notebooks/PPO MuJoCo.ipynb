{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d63649e",
   "metadata": {},
   "source": [
    "\n",
    "# PPO for Mujoco\n",
    "\n",
    "This is a reduced version of PPO as used for MuJoCO (at least how I understand it).\n",
    "\n",
    "This means:\n",
    "- use of GAE($\\lambda$)\n",
    "- collection of many time steps, even if it means that several episodes are collected\n",
    "- Clip objective\n",
    "\n",
    "Additionally: \n",
    "- counting time-steps rather than episodes\n",
    "- one set of hyper-parameters for all environments\n",
    "\n",
    "By my interpretation, several pieces of the full PPO algorithm are not used for MuJoCo (e.g., see Table 3 on page 10 of [the PPO paper](https://arxiv.org/abs/1707.06347)):\n",
    "- no mention of more than one actor\n",
    "- no mention of use of KL divergence or adaptive KL step-size, or entropy bonus, in the best result (see Table 1, and compare hyper-parameter settings for Roboschool and Atari, Tables 4 and 5, where there is mention of these approaches, but not for MuJoCo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a39332cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RescaleAction\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torchrl.modules import TruncatedNormal # continous bounded action space\n",
    "\n",
    "import copy # to save the old policy\n",
    "import random # sample losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9192a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The policy needs to be modified to return a mean tensor and a standard deviations tensor\n",
    "# - use logits as mean\n",
    "# - standard deviations separate\n",
    "# - no dependencies between dimensions of multi-variate normal distribution\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden1, n_hidden2, n_out):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden1, n_hidden2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden2, n_out),\n",
    "        )\n",
    "        # self.sm = nn.Softmax(dim=0) # probabilities to choose an action\n",
    "        # self.lsm = nn.LogSoftmax(dim=0) # for log probabilities used in the gradient for REINFORCE\n",
    "\n",
    "        # From PPO, page 6: \n",
    "        # \"To represent the policy, we used a fully-connected MLP with two hidden layers of 64 units,\n",
    "        # and tanh nonlinearities, outputting the mean of a Gaussian distribution, with variable standard\n",
    "        # deviations, following [Sch+15b; Dua+16].\"\n",
    "        # (See [Sch+15b] (Trust Region Policy Optimization) on page 15.)\n",
    "        # Initialization of the standard deviations is not fully clear here, \n",
    "        # but to initialize them to 1 seems a reasonable first guess.\n",
    "        self.log_stddevs = nn.Parameter(torch.zeros(n_out))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.net(x)\n",
    "        # probs = self.sm(logits)\n",
    "        # scores = self.lsm(logits)\n",
    "        # return probs, scores, logits # we include the logits in the output for use in the state-value function\n",
    "        stddevs = torch.exp(self.log_stddevs)\n",
    "        return logits, stddevs\n",
    "    \n",
    "class Value(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden1, n_hidden2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_in, n_hidden1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden1, n_hidden2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden2, 1), # same as Policy, but output is only one number\n",
    "        )\n",
    "    \n",
    "    def forward(self, x): \n",
    "        logit = self.net(x)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35df41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Env name: InvertedPendulum-v5, \n",
      "- Observation space: Box(-inf, inf, (4,), float64) \n",
      "- Action space:      Box(-1.0, 1.0, (1,), float32) \n",
      "- Reward threshold: 950.0\n",
      "\n",
      "Env name: InvertedDoublePendulum-v5, \n",
      "- Observation space: Box(-inf, inf, (9,), float64) \n",
      "- Action space:      Box(-1.0, 1.0, (1,), float32) \n",
      "- Reward threshold: 9100.0\n",
      "\n",
      "Env name: Reacher-v5, \n",
      "- Observation space: Box(-inf, inf, (10,), float64) \n",
      "- Action space:      Box(-1.0, 1.0, (2,), float32) \n",
      "- Reward threshold: -3.75\n",
      "\n",
      "Env name: HalfCheetah-v5, \n",
      "- Observation space: Box(-inf, inf, (17,), float64) \n",
      "- Action space:      Box(-1.0, 1.0, (6,), float32) \n",
      "- Reward threshold: 4800.0\n",
      "\n",
      "Env name: Hopper-v5, \n",
      "- Observation space: Box(-inf, inf, (11,), float64) \n",
      "- Action space:      Box(-1.0, 1.0, (3,), float32) \n",
      "- Reward threshold: 3800.0\n",
      "\n",
      "Env name: Walker2d-v5, \n",
      "- Observation space: Box(-inf, inf, (17,), float64) \n",
      "- Action space:      Box(-1.0, 1.0, (6,), float32) \n",
      "- Reward threshold: None\n",
      "\n",
      "Env name: Swimmer-v5, \n",
      "- Observation space: Box(-inf, inf, (8,), float64) \n",
      "- Action space:      Box(-1.0, 1.0, (2,), float32) \n",
      "- Reward threshold: 360.0\n"
     ]
    }
   ],
   "source": [
    "envs = [\n",
    "    \"InvertedPendulum-v5\",\n",
    "    \"InvertedDoublePendulum-v5\",\n",
    "    \"Reacher-v5\",\n",
    "    \"HalfCheetah-v5\",\n",
    "    \"Hopper-v5\",\n",
    "    \"Walker2d-v5\",\n",
    "    \"Swimmer-v5\"\n",
    "]\n",
    "from gymnasium.wrappers import RescaleAction\n",
    "for env_name in envs:\n",
    "    env = gym.make(env_name)\n",
    "    wrapped_env = RescaleAction(env, min_action=-1, max_action=1)\n",
    "    wrapped_env.reset()\n",
    "    print(\"\\nEnv name: {}, \\n- Observation space: {} \\n- Action space:      {} \\n- Reward threshold: {}\".format(env_name, wrapped_env.observation_space, wrapped_env.action_space, env.spec.reward_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aaf7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "env_name = \"InvertedDoublePendulum-v5\"\n",
    "\n",
    "n_hidden1 = 64 \n",
    "n_hidden2 = 64\n",
    "\n",
    "gamma = 0.99\n",
    "gae_lambda = 0.95 # New parameter for GAE\n",
    "\n",
    "eps = 0.2 # New clipping parameter\n",
    "\n",
    "# Sutton & Barto use a separate learning rate to update the state-value function parameters\n",
    "# PPO has the same learning rate for both policy and value function\n",
    "alpha = 3e-4\n",
    "\n",
    "n_steps = 100 # TODO this should be reinterpreted as total number of interactions with the environment\n",
    "T = 128 # 2048\n",
    "n_epochs = 1 # 10\n",
    "minibatch_size = 128 # 64\n",
    "\n",
    "print_every_n_steps = 1\n",
    "early_stopping = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341cd8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 1 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "\n",
      "Step: 2 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "\n",
      "Step: 3 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "\n",
      "Step: 4 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "\n",
      "Step: 5 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "\n",
      "Step: 6 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 45.28244542252317\n",
      "\n",
      "Step: 7 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 46.95982928919041\n",
      "\n",
      "Step: 8 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 49.37403209433042\n",
      "\n",
      "Step: 9 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 49.930046551743835\n",
      "\n",
      "Step: 10 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 52.89727686198648\n",
      "\n",
      "Step: 11 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 54.11674966821556\n",
      "\n",
      "Step: 12 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 54.49393260462739\n",
      "\n",
      "Step: 13 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 54.02132501199285\n",
      "\n",
      "Step: 14 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 52.61365047067641\n",
      "\n",
      "Step: 15 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 53.2813839192243\n",
      "\n",
      "Step: 16 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 51.680699765708034\n",
      "\n",
      "Step: 17 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 51.682463263885545\n",
      "\n",
      "Step: 18 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 53.00766811685496\n",
      "\n",
      "Step: 19 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 54.97869117934718\n",
      "\n",
      "Step: 20 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 56.07805086211153\n",
      "\n",
      "Step: 21 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 55.01423881874117\n",
      "\n",
      "Step: 22 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 55.684835621075756\n",
      "\n",
      "Step: 23 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 57.16980174305606\n",
      "\n",
      "Step: 24 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 56.88461522666369\n",
      "\n",
      "Step: 25 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 55.48970827259092\n",
      "\n",
      "Step: 26 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 56.47200172691739\n",
      "\n",
      "Step: 27 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 57.97198578959763\n",
      "\n",
      "Step: 28 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 58.81106677704415\n",
      "\n",
      "Step: 29 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 59.56555173055482\n",
      "\n",
      "Step: 30 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 60.51936488772586\n",
      "\n",
      "Step: 31 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 62.0871315498274\n",
      "\n",
      "Step: 32 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 63.473232680217336\n",
      "\n",
      "Step: 33 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 62.17656198698121\n",
      "\n",
      "Step: 34 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 62.914781665215095\n",
      "\n",
      "Step: 35 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 62.34135897665535\n",
      "\n",
      "Step: 36 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 60.53224735575796\n",
      "\n",
      "Step: 37 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 59.31859582140182\n",
      "\n",
      "Step: 38 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 59.120978641068184\n",
      "\n",
      "Step: 39 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 61.368080561990276\n",
      "\n",
      "Step: 40 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 62.49793245118221\n",
      "\n",
      "Step: 41 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 61.486338948594785\n",
      "\n",
      "Step: 42 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 62.408683584298366\n",
      "\n",
      "Step: 43 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 62.529625824932054\n",
      "\n",
      "Step: 44 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 62.52986913756774\n",
      "\n",
      "Step: 45 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 63.53480262856878\n",
      "\n",
      "Step: 46 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 61.48071751252681\n",
      "\n",
      "Step: 47 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 63.064610455839805\n",
      "\n",
      "Step: 48 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 65.14820301128303\n",
      "\n",
      "Step: 49 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 64.96874704255211\n",
      "\n",
      "Step: 50 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 66.44206259015874\n",
      "\n",
      "Step: 51 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 66.90926849283169\n",
      "\n",
      "Step: 52 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 68.42319867418209\n",
      "\n",
      "Step: 53 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 67.57733117456115\n",
      "\n",
      "Step: 54 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 68.11097320700812\n",
      "\n",
      "Step: 55 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 67.905145254852\n",
      "\n",
      "Step: 56 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 66.14711134478144\n",
      "\n",
      "Step: 57 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 66.75607606047322\n",
      "\n",
      "Step: 58 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 66.64935915291481\n",
      "\n",
      "Step: 59 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 67.29813847002272\n",
      "\n",
      "Step: 60 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 68.79073814684031\n",
      "\n",
      "Step: 61 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 68.33440115398463\n",
      "\n",
      "Step: 62 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 70.20971495893465\n",
      "\n",
      "Step: 63 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 70.5907313425052\n",
      "\n",
      "Step: 64 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 71.5963575588607\n",
      "\n",
      "Step: 65 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 70.55727323666966\n",
      "\n",
      "Step: 66 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 71.22018492159219\n",
      "\n",
      "Step: 67 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 72.07432116857994\n",
      "\n",
      "Step: 68 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 73.09810236228425\n",
      "\n",
      "Step: 69 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 73.83693121994659\n",
      "\n",
      "Step: 70 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 72.12957876996819\n",
      "\n",
      "Step: 71 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 72.03330646893964\n",
      "\n",
      "Step: 72 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 72.33968991664975\n",
      "\n",
      "Step: 73 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 72.34187313208903\n",
      "\n",
      "Step: 74 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 71.4921566780071\n",
      "\n",
      "Step: 75 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 72.72841368009152\n",
      "\n",
      "Step: 76 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 72.720169289989\n",
      "\n",
      "Step: 77 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 74.88729425451112\n",
      "\n",
      "Step: 78 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 75.27294821670894\n",
      "\n",
      "Step: 79 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 76.38776293318558\n",
      "\n",
      "Step: 80 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 77.24556389959318\n",
      "\n",
      "Step: 81 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 79.776562241482\n",
      "\n",
      "Step: 82 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 79.58290541630204\n",
      "\n",
      "Step: 83 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 80.33311329998443\n",
      "\n",
      "Step: 84 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 78.750244665239\n",
      "\n",
      "Step: 85 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 80.15637772308479\n",
      "\n",
      "Step: 86 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 80.81034691658128\n",
      "\n",
      "Step: 87 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 80.90364605790593\n",
      "\n",
      "Step: 88 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 81.36975372100123\n",
      "\n",
      "Step: 89 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 80.8992052961656\n",
      "\n",
      "Step: 90 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 80.08692927435062\n",
      "\n",
      "Step: 91 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 79.60536834045618\n",
      "\n",
      "Step: 92 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 80.17068850653918\n",
      "\n",
      "Step: 93 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 78.03786315026622\n",
      "\n",
      "Step: 94 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 78.22164560450771\n",
      "\n",
      "Step: 95 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 77.66480975672015\n",
      "\n",
      "Step: 96 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 76.33747144209198\n",
      "\n",
      "Step: 97 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 75.96248203816\n",
      "\n",
      "Step: 98 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 78.65676801408816\n",
      "\n",
      "Step: 99 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 79.20439396792304\n",
      "\n",
      "Step: 100 of 100\n",
      "Alpha: 0.0003 Gamma: 0.99 Lambda: 0.95\n",
      "Average reward last 100 episodes: 79.69519673838039\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Initialise the environment\n",
    "env = gym.make(env_name)\n",
    "wrapped_env = RescaleAction(env, min_action=-1, max_action=1)\n",
    "\n",
    "# Reset the environment to generate the first observation\n",
    "observation, info = env.reset(seed=seed)\n",
    "observation = torch.tensor(observation, requires_grad=False, dtype=torch.float32)\n",
    "\n",
    "policy = Policy(n_in=env.observation_space.shape[0], n_hidden1=n_hidden1, n_hidden2=n_hidden2, n_out=env.action_space.shape[0])\n",
    "\n",
    "# The state-value function maps states to a single number. From PPO: \"We donâ€™t share parameters between the policy and value function [...]\". \n",
    "value = Value(n_in=env.observation_space.shape[0], n_hidden1=n_hidden1, n_hidden2=n_hidden2)\n",
    "\n",
    "# Sutton & Barto use separate gradient update steps with separate learning rates for the policy and the state-value function\n",
    "# PPO has the same learning rate for both policy and value function\n",
    "optimizer = torch.optim.Adam(list(policy.parameters()) + list(value.parameters()), lr=alpha, maximize=True)\n",
    "\n",
    "all_episode_rewards = []\n",
    "\n",
    "for i_global_timestep in range(1, n_steps+1):\n",
    "    \n",
    "    # track information for roll-outs in the form of nested lists, where the total number of elements is T, \n",
    "    # and the inner lists are episodes\n",
    "    rewards_horizon = []\n",
    "    observations_horizon = []\n",
    "    actions_horizon = []\n",
    "    values_horizon = [] # also track the value function\n",
    "    \n",
    "    # informaton per episode, in the form (s_t, a_t) -> (r_t, s_{t+1})\n",
    "    rewards_episode = [] # T rewards from 1 to T\n",
    "    observations_episode = [observation] # T observations from 0 to T-1, the policy expects tensors as input\n",
    "    actions_episode = [] # T actions from 0 to T-1\n",
    "    values_episode = [value(observation)] # same as observations, but if episode ends one 0 will be appended\n",
    "\n",
    "    # roll-out of episode(s) following the policy, for T total time-steps\n",
    "    done = False\n",
    "    i_horizon_timestep = 0\n",
    "    while i_horizon_timestep < T:\n",
    "        \n",
    "        # probabilities for actions\n",
    "        # Change 1: The policy network outputs means and standard deviations\n",
    "        pred_means, pred_stddevs = policy(observation)\n",
    "        \n",
    "        # sample an action according to the probabilities\n",
    "        # Change 2: We use the truncated normal distribution on the continuous action space, not the categorical distribution for a discrete set of actions\n",
    "        TN = TruncatedNormal(loc=pred_means,\n",
    "                            scale=pred_stddevs,\n",
    "                            low=env.action_space.low,\n",
    "                            high=env.action_space.high,\n",
    "                            tanh_loc=False)\n",
    "        action = TN.sample()\n",
    "\n",
    "        # step (transition) through the environment with the action\n",
    "        # receiving the next observation, reward and if the episode has terminated or truncated\n",
    "        observation, reward, terminated, truncated, info = env.step(action.detach().numpy())\n",
    "        i_horizon_timestep += 1\n",
    "        observation = torch.tensor(observation, requires_grad=False, dtype=torch.float32)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # build up one episode\n",
    "        rewards_episode.append(reward)\n",
    "        observations_episode.append(observation)\n",
    "        actions_episode.append(action)\n",
    "        values_episode.append(value(observation)) # this is the observation after taking action # TODO: for episode roll out, don't need it here! \n",
    "\n",
    "        # If the episode or the time-steps have ended then we can reset to start a new episode\n",
    "        if done or i_horizon_timestep == T:\n",
    "            observation, info = env.reset()\n",
    "            observation = torch.tensor(observation, requires_grad=False, dtype=torch.float32)\n",
    "            \n",
    "            # track quantities per episode\n",
    "            rewards_horizon.append(rewards_episode)\n",
    "            observations_horizon.append(observations_episode)\n",
    "            actions_horizon.append(actions_episode)\n",
    "            if done:\n",
    "                values_episode[-1] = torch.zeros_like(values_episode[-1]) # value for next observation after termination should be 0\n",
    "                all_episode_rewards.append(sum(rewards_episode)) # track total reward for all episodes\n",
    "            values_horizon.append(values_episode)\n",
    "            # and reset them\n",
    "            rewards_episode = [] # T rewards from 1 to T\n",
    "            observations_episode = [observation] # T observations from 0 to T-1, the policy expects tensors as input\n",
    "            actions_episode = []\n",
    "            values_episode = [value(observation)] # TODO would the values need to be updated after a gradient step\n",
    "\n",
    "            done = False # start new episode\n",
    "    \n",
    "\n",
    "    policy_old = copy.deepcopy(policy) # save the old policy\n",
    "\n",
    "\n",
    "    # TODO insert here computation of things that are fixed per rollout, and don't depend on the updated policy (A's)\n",
    "\n",
    "\n",
    "    # For each episode, pick the indices of the steps to be used to update the policy\n",
    "    loss_indices = list(range(T))\n",
    "    random.shuffle(loss_indices)\n",
    "\n",
    "    for i_epoch in range(n_epochs):\n",
    "        \n",
    "\n",
    "        # TODO review loss\n",
    "        # Calculate loss\n",
    "        # policy updates using policy gradients along each step of the episode\n",
    "        # We accumulate gradients over one episode and make only one gradient step per episode\n",
    "        pseudo_losses = []\n",
    "        value_losses = []\n",
    "        # we now unpack the nested list structure\n",
    "        for i_ep, rewards_episode in enumerate(rewards_horizon): # TODO for efficiency this could be done only for those indices that are selected for update in this epoch\n",
    "            observations_episode = observations_horizon[i_ep]\n",
    "            actions_episode = actions_horizon[i_ep]\n",
    "            values_episode = values_horizon[i_ep]\n",
    "            for t in range(len(rewards_episode)):\n",
    "                \n",
    "                observation = observations_episode[t]\n",
    "                action = actions_episode[t]\n",
    "\n",
    "                rewards_ge_t = rewards_episode[t:T]\n",
    "                values_ge_t = values_episode[t:T+1][:-1]\n",
    "                values_ge_tp1 = values_episode[t:T+1][1:]\n",
    "                \n",
    "                deltas_ge_t = [r + gamma*vnext - v for r,vnext,v in zip(rewards_ge_t, values_ge_t, values_ge_tp1)]\n",
    "\n",
    "                Advantage_t = sum((gamma * gae_lambda)**i * d for i, d in enumerate(deltas_ge_t)) # TODO Advantages don't change when updating the policy - don't recalculate them for every epoch\n",
    "\n",
    "                Advantage_t = Advantage_t.detach()\n",
    "\n",
    "                # log probs for this observation - action under updated policy\n",
    "                pred_means, pred_stddevs = policy(observation)\n",
    "                TN = TruncatedNormal(loc=pred_means,\n",
    "                                    scale=pred_stddevs,\n",
    "                                    low=env.action_space.low,\n",
    "                                    high=env.action_space.high,\n",
    "                                    tanh_loc=False)\n",
    "\n",
    "                log_prob = TN.log_prob(action).sum()\n",
    "\n",
    "                # log probs for this observation - action under old policy\n",
    "                pred_means_old, pred_stddevs_old = policy_old(observation) # TODO we could also save these instead of evaluating the policy again\n",
    "                TN_old = TruncatedNormal(loc=pred_means_old,\n",
    "                                        scale=pred_stddevs_old,\n",
    "                                        low=env.action_space.low,\n",
    "                                        high=env.action_space.high,\n",
    "                                        tanh_loc=False)\n",
    "\n",
    "                log_prob_old = TN_old.log_prob(action).sum().detach() # TODO can compute and store these during episode rollouts\n",
    "                \n",
    "                # ratio\n",
    "                r_t = torch.exp(log_prob - log_prob_old) # exp(log a - log b) = exp(log a) / exp(log b) = a / b\n",
    "\n",
    "                # Clipped objective\n",
    "                L_clip = torch.min(r_t*Advantage_t, torch.clamp(r_t, 1-eps, 1+eps)*Advantage_t)\n",
    "\n",
    "                # Value loss, now in form of MSE loss, using: V - V_target = Advantage = V - V + Advantage = V - (Advantage + V)\n",
    "                L_value = 0.5 * (value(observation) - (Advantage_t + values_episode[t].detach()))**2\n",
    "\n",
    "                pseudo_losses.append(L_clip - L_value) # now joinly optimize all objectives / losses\n",
    "\n",
    "\n",
    "        # stupid custom version of sampling without replacement, but in a way that allows additional epochs even when all elements have already been sampled\n",
    "        epoch_indices = loss_indices[:minibatch_size]\n",
    "        del loss_indices[:minibatch_size] # \"popleft\"\n",
    "        loss_indices.extend(epoch_indices) # and then insert back in\n",
    "        \n",
    "        # select only losses (indexed by steps in the environment) for a selected sample of steps\n",
    "        pseudo_loss = torch.stack([pseudo_losses[i] for i in epoch_indices]).mean()\n",
    "        \n",
    "        # Now one joint optimization\n",
    "        optimizer.zero_grad()\n",
    "        pseudo_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # print some statistics every other step\n",
    "    if i_global_timestep % print_every_n_steps == 0:\n",
    "        print(\"\\nStep:\", i_global_timestep, \"of\", n_steps)\n",
    "        print(\"Alpha:\", alpha, \"Gamma:\", gamma, \"Lambda:\", gae_lambda)\n",
    "        if len(all_episode_rewards) > 100: print(\"Average reward last 100 episodes:\", np.mean(all_episode_rewards[-100:]))\n",
    "\n",
    "    # TODO early stopping needs lower average reward bound applicable for several environments. Reward scaling and max_timesteps -> gives lower bound for reward per episode?\n",
    "    # TODO move early stopping and printing before the gradient updates\n",
    "    # if early_stopping and i_episode > 4000 and np.mean(all_episode_rewards[-200:]) < -200:\n",
    "    #     print(\"Run terminated due to early stopping at episode\", i_episode)\n",
    "    #     break\n",
    "\n",
    "    # - When a policy solved the environment for one episode:\n",
    "    if all_episode_rewards[-1] > env.spec.reward_threshold:\n",
    "        print(\"Environment was solved for one episode at step\", i_global_timestep)\n",
    "        \n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72502c7f",
   "metadata": {},
   "source": [
    "### Save and load trained policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a7f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Uncomment to save a trained policy:\n",
    "# pickle.dump(policy, open('policies/REINFORCE_with_baseline_InvertedDoublePendulum_visualize.pkl', 'wb'))\n",
    "\n",
    "# Uncomment to load a saved policy:\n",
    "# policy = pickle.load(open('policies/REINFORCE_with_baseline_InvertedDoublePendulum_visualize.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97620443",
   "metadata": {},
   "source": [
    "### Plotting training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d462eeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7cdccf29b450>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "smoothing_interval = 100 # Change for different levels of smoothing\n",
    "smoothed_rewards = np.convolve(all_episode_rewards, np.ones(smoothing_interval)/smoothing_interval, 'valid')\n",
    "\n",
    "\n",
    "plt.plot(smoothed_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25132b",
   "metadata": {},
   "source": [
    "## Visualize the policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7de8054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video generation does not yet work yet for me"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
